{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 189983,
          "sourceType": "datasetVersion",
          "datasetId": 81794
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Garbage classification",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "asdasdasasdas_garbage_classification_path = kagglehub.dataset_download('asdasdasasdas/garbage-classification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "-WvnnnGheUqm",
        "outputId": "44ecce98-02c6-4224-a0ee-1d4aef409a5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:44:09.20794Z",
          "iopub.execute_input": "2025-07-03T09:44:09.208204Z",
          "iopub.status.idle": "2025-07-03T09:44:18.369872Z",
          "shell.execute_reply.started": "2025-07-03T09:44:09.208181Z",
          "shell.execute_reply": "2025-07-03T09:44:18.369105Z"
        },
        "id": "5DnWjzdbeUqr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the dataset"
      ],
      "metadata": {
        "id": "cmFqeaC6eUqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_path = Path('/kaggle/input/garbage-classification/Garbage classification/Garbage classification')\n",
        "\n",
        "print(image_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:44:18.371299Z",
          "iopub.execute_input": "2025-07-03T09:44:18.371762Z",
          "iopub.status.idle": "2025-07-03T09:44:18.376126Z",
          "shell.execute_reply.started": "2025-07-03T09:44:18.37174Z",
          "shell.execute_reply": "2025-07-03T09:44:18.375395Z"
        },
        "id": "1lnm1QKGeUqv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
        "    print(root)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:44:18.376905Z",
          "iopub.execute_input": "2025-07-03T09:44:18.377115Z",
          "iopub.status.idle": "2025-07-03T09:44:37.866764Z",
          "shell.execute_reply.started": "2025-07-03T09:44:18.377099Z",
          "shell.execute_reply": "2025-07-03T09:44:37.866119Z"
        },
        "id": "7ChINmdzeUqx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I checked classes of trashes classified in dataset"
      ],
      "metadata": {
        "id": "s788rbOfeUqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir  = '/kaggle/input/garbage-classification/Garbage classification/Garbage classification'\n",
        "classes = os.listdir(data_dir)\n",
        "print(classes)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:44:37.868478Z",
          "iopub.execute_input": "2025-07-03T09:44:37.868715Z",
          "iopub.status.idle": "2025-07-03T09:44:37.873021Z",
          "shell.execute_reply.started": "2025-07-03T09:44:37.868698Z",
          "shell.execute_reply": "2025-07-03T09:44:37.872343Z"
        },
        "id": "xbYAJtJHeUqz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transform the data to structure appropied for analysis.\n",
        "\n",
        "**Resize** - 256x256 pixels.\n",
        "\n",
        "**ToTensor()**\n",
        "Converts a PIL (or NumPy) image to a PyTorch tensor of type torch.\n",
        "\n",
        "\n",
        "FloatTensor Scales pixel values from [0, 255] → [0.0, 1.0] by dividing by 255./ float value\n",
        "\n",
        "\n",
        "Converts a shape from (height, width, channels) → (channels, height, width)."
      ],
      "metadata": {
        "id": "zwPyKmtPeUq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = ImageFolder(data_dir, transform=transform)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:44:37.87367Z",
          "iopub.execute_input": "2025-07-03T09:44:37.873867Z",
          "iopub.status.idle": "2025-07-03T09:44:39.439448Z",
          "shell.execute_reply.started": "2025-07-03T09:44:37.873853Z",
          "shell.execute_reply": "2025-07-03T09:44:39.438717Z"
        },
        "id": "81zwrpROeUq1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset structure and examples\n",
        "I checked how many imagines is in dataset, show a sample of foto and printe the structure of dataset - how many of each classess of trashes is in the presented dataset"
      ],
      "metadata": {
        "id": "n62qrzGueUq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def show_sample(img, label):\n",
        "    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "\n",
        "img, label = dataset[1520]\n",
        "show_sample(img, label)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:44:39.440244Z",
          "iopub.execute_input": "2025-07-03T09:44:39.440441Z",
          "iopub.status.idle": "2025-07-03T09:44:39.807618Z",
          "shell.execute_reply.started": "2025-07-03T09:44:39.440424Z",
          "shell.execute_reply": "2025-07-03T09:44:39.806963Z"
        },
        "id": "ETi0u2FZeUq2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of imagines: {len(dataset)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:44:39.808447Z",
          "iopub.execute_input": "2025-07-03T09:44:39.808721Z",
          "iopub.status.idle": "2025-07-03T09:44:39.812986Z",
          "shell.execute_reply.started": "2025-07-03T09:44:39.808701Z",
          "shell.execute_reply": "2025-07-03T09:44:39.81203Z"
        },
        "id": "h5FKsa8neUq3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "labels = [label for _, label in dataset]\n",
        "class_counts = Counter(labels)\n",
        "\n",
        "for i, count in class_counts.items():\n",
        "    class_name = dataset.classes[i]\n",
        "    print(f\"Class '{class_name}': {count} imagines\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:44:39.813785Z",
          "iopub.execute_input": "2025-07-03T09:44:39.81428Z",
          "iopub.status.idle": "2025-07-03T09:45:06.251498Z",
          "shell.execute_reply.started": "2025-07-03T09:44:39.814262Z",
          "shell.execute_reply": "2025-07-03T09:45:06.250891Z"
        },
        "id": "U0TUFT-9eUq3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I split data set into train, test and validation data"
      ],
      "metadata": {
        "id": "glTDDL3reUq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.1 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:06.25217Z",
          "iopub.execute_input": "2025-07-03T09:45:06.252744Z",
          "iopub.status.idle": "2025-07-03T09:45:07.084426Z",
          "shell.execute_reply.started": "2025-07-03T09:45:06.252726Z",
          "shell.execute_reply": "2025-07-03T09:45:07.083739Z"
        },
        "id": "qS1PWuwbeUq5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader - a interesting formula for \"packing\" the imagines in designed bath size structure (in my case 32 imagine per package)\n",
        "Why we can/should used it?\n",
        "\n",
        "* Loading data in batches - instead of feeding the model one image at a time, you load a group (e.g. 32 images at once), which speeds up training.\n",
        "\n",
        "* Random mixing of data (shuffle) - so that the model does not learn the order, which may be random, but sees the data in a random order (important for training).\n",
        "\n",
        "* Easy iteration over data - DataLoader is iterable, so you can easily write training loops.\n",
        "\n",
        "* Loading data in the background (multi-threading) - DataLoader can use multiple threads to prepare subsequent batches, so as not to wait for disk."
      ],
      "metadata": {
        "id": "UblUf4AMeUq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:07.086613Z",
          "iopub.execute_input": "2025-07-03T09:45:07.086825Z",
          "iopub.status.idle": "2025-07-03T09:45:07.091502Z",
          "shell.execute_reply.started": "2025-07-03T09:45:07.086809Z",
          "shell.execute_reply": "2025-07-03T09:45:07.090974Z"
        },
        "id": "dI2HOxWdeUq7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An example of single batch"
      ],
      "metadata": {
        "id": "fryRDmH6eUq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow = 16).permute(1, 2, 0))\n",
        "        break\n",
        "\n",
        "show_batch(train_loader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:07.092345Z",
          "iopub.execute_input": "2025-07-03T09:45:07.092641Z",
          "iopub.status.idle": "2025-07-03T09:45:07.923103Z",
          "shell.execute_reply.started": "2025-07-03T09:45:07.092617Z",
          "shell.execute_reply": "2025-07-03T09:45:07.922286Z"
        },
        "id": "bo7bGk23eUq8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pre-trained model\n",
        "\n",
        "The ResNet50 model was trained on the massive ImageNet dataset and “learned” to detect basic patterns and features in images (e.g. edges, textures)\n"
      ],
      "metadata": {
        "id": "cqjZgHPWeUq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:07.923891Z",
          "iopub.execute_input": "2025-07-03T09:45:07.924351Z",
          "iopub.status.idle": "2025-07-03T09:45:09.03233Z",
          "shell.execute_reply.started": "2025-07-03T09:45:07.924329Z",
          "shell.execute_reply": "2025-07-03T09:45:09.031576Z"
        },
        "id": "kv0B7C_-eUq9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Freezing layers\n",
        "\n",
        "1. Faster training and lower hardware requirements\n",
        "\n",
        "You don't have to calculate gradients for the entire network - you save memory and time.\n",
        "\n",
        "2. Transfer learning - using pre-trained features\n",
        "\n",
        "If your problem is similar (e.g. image classification), you often don't need to change the entire network, just adapt it to your classes.\n",
        "\n",
        "By freezing the layers, you preserve these \"trained\" features and only train the last layer, which adapts the output to your classes.\n",
        "\n",
        "3. Prevents overfitting with small amounts of data\n",
        "\n",
        "If you have few images, then training the entire network from scratch can lead to overfitting - the model will \"remember\" the data instead of learning general patterns.\n",
        "\n",
        "Freezing most of the layers allows you to train fewer parameters and be more stable."
      ],
      "metadata": {
        "id": "9toRPgH7eUq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:09.033124Z",
          "iopub.execute_input": "2025-07-03T09:45:09.033325Z",
          "iopub.status.idle": "2025-07-03T09:45:09.037578Z",
          "shell.execute_reply.started": "2025-07-03T09:45:09.03331Z",
          "shell.execute_reply": "2025-07-03T09:45:09.036842Z"
        },
        "id": "my7rrhJPeUq9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we have a classification problem with garbage classification we need to adjust the last layer for amount of classes we have in our dataset. Garbage classification contains 6 classess of diffrent trashes."
      ],
      "metadata": {
        "id": "zTt7FKaKeUq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 6\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:09.038202Z",
          "iopub.execute_input": "2025-07-03T09:45:09.03837Z",
          "iopub.status.idle": "2025-07-03T09:45:09.053029Z",
          "shell.execute_reply.started": "2025-07-03T09:45:09.038357Z",
          "shell.execute_reply": "2025-07-03T09:45:09.052508Z"
        },
        "id": "LiE_15EbeUq-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer the model to GPU if available"
      ],
      "metadata": {
        "id": "aqOqt5mieUq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:09.053566Z",
          "iopub.execute_input": "2025-07-03T09:45:09.053831Z",
          "iopub.status.idle": "2025-07-03T09:45:09.395177Z",
          "shell.execute_reply.started": "2025-07-03T09:45:09.05381Z",
          "shell.execute_reply": "2025-07-03T09:45:09.394633Z"
        },
        "id": "6PiOJ7XjeUq_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we have here - we creates a loss function..\n",
        "\n",
        "* CrossEntropyLoss is a typical function for  used in multi-class classification.\n",
        "* optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "Creates an optimizer that updates the model parameters after each iteration to minimize the loss.\n",
        "\n",
        "We use Adam - a modern optimizer, better than classic SGD in most cases.\n",
        "\n",
        "model.fc.parameters() means that we optimize only the last layer (fc), and the rest of the network (frozen earlier) is not trained.\n",
        "lr=0.001 is the learning rate - how fast the model learns."
      ],
      "metadata": {
        "id": "QxAyfLNceUq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:09.395914Z",
          "iopub.execute_input": "2025-07-03T09:45:09.396177Z",
          "iopub.status.idle": "2025-07-03T09:45:09.400162Z",
          "shell.execute_reply.started": "2025-07-03T09:45:09.396152Z",
          "shell.execute_reply": "2025-07-03T09:45:09.399635Z"
        },
        "id": "bgZOze1DeUq_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:09.400866Z",
          "iopub.execute_input": "2025-07-03T09:45:09.40114Z",
          "iopub.status.idle": "2025-07-03T09:45:23.90516Z",
          "shell.execute_reply.started": "2025-07-03T09:45:09.401125Z",
          "shell.execute_reply": "2025-07-03T09:45:23.904234Z"
        },
        "id": "Ki5mqI1oeUrA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Validation accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:23.906026Z",
          "iopub.execute_input": "2025-07-03T09:45:23.906292Z",
          "iopub.status.idle": "2025-07-03T09:45:25.899077Z",
          "shell.execute_reply.started": "2025-07-03T09:45:23.906265Z",
          "shell.execute_reply": "2025-07-03T09:45:25.898395Z"
        },
        "id": "GIPWHQsEeUrA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ~80 % accuracy -not bad but I prefer a better outcome !"
      ],
      "metadata": {
        "id": "RtZiQAb3eUrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An improved approach"
      ],
      "metadata": {
        "id": "lhc8-NKEeUrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomResizedCrop(224) Crops a random fragment and scales it to 224×224 px. Increases crop diversity — the model doesn't get used to a fixed composition.\n",
        "\n",
        "RandomHorizontalFlip() Randomly flips the image horizontally. Helps when left/right doesn't matter (e.g. junk).\n",
        "\n",
        "RandomRotation(10) Rotates the image randomly by max 10°. The model learns to be resistant to slight rotations.\n",
        "\n",
        "ColorJitter(...) Changes brightness, contrast, saturation, hue. The model doesn't learn only colors — shape, texture are more important.\n",
        "\n",
        "ToTensor() Converts the image from PIL → PyTorch Tensor (0–1). Tensor is a format required by PyTorch.\n",
        "\n",
        "Normalize(...) Normalizes RGB values (mean/std from ImageNet). ResNet50 was trained on such normalized images — it needs to get data in the same format.\n"
      ],
      "metadata": {
        "id": "ntUjpsBLeUrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform_imp = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:25.899909Z",
          "iopub.execute_input": "2025-07-03T09:45:25.900165Z",
          "iopub.status.idle": "2025-07-03T09:45:25.90454Z",
          "shell.execute_reply.started": "2025-07-03T09:45:25.900148Z",
          "shell.execute_reply": "2025-07-03T09:45:25.903993Z"
        },
        "id": "j7zJTSg9eUrC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_test_transform_imp = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:25.905311Z",
          "iopub.execute_input": "2025-07-03T09:45:25.905689Z",
          "iopub.status.idle": "2025-07-03T09:45:25.921174Z",
          "shell.execute_reply.started": "2025-07-03T09:45:25.905667Z",
          "shell.execute_reply": "2025-07-03T09:45:25.920533Z"
        },
        "id": "vQtv4wIEeUrC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset_imp = datasets.ImageFolder(data_dir, transform=train_transform_imp)\n",
        "num_classes = len(full_dataset_imp.classes)\n",
        "print(num_classes)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:25.921923Z",
          "iopub.execute_input": "2025-07-03T09:45:25.92253Z",
          "iopub.status.idle": "2025-07-03T09:45:26.245925Z",
          "shell.execute_reply.started": "2025-07-03T09:45:25.922513Z",
          "shell.execute_reply": "2025-07-03T09:45:26.245374Z"
        },
        "id": "Y2h70ZgueUrD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_size_imp = int(0.7 * len(full_dataset_imp))\n",
        "val_size_imp = int(0.15 * len(full_dataset_imp))\n",
        "test_size_imp = len(full_dataset_imp) - train_size_imp - val_size_imp\n",
        "train_dataset_imp, val_dataset_imp, test_dataset_imp = random_split(full_dataset_imp, [train_size_imp, val_size_imp, test_size_imp])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.2467Z",
          "iopub.execute_input": "2025-07-03T09:45:26.247307Z",
          "iopub.status.idle": "2025-07-03T09:45:26.251215Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.24729Z",
          "shell.execute_reply": "2025-07-03T09:45:26.250446Z"
        },
        "id": "jvJgEXmoeUrD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For validation and test, we don't want to change images randomly. We want to know:**\n",
        "\n",
        "\"Does the model classify data that is as it is in real life?\"\n",
        "\n",
        "From now on, validation (and test) will use different, more relaxed transformations\" — e.g., without augmentation."
      ],
      "metadata": {
        "id": "JHp6UItQeUrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset_imp.dataset.transform = val_test_transform_imp\n",
        "test_dataset_imp.dataset.transform = val_test_transform_imp"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.252051Z",
          "iopub.execute_input": "2025-07-03T09:45:26.252287Z",
          "iopub.status.idle": "2025-07-03T09:45:26.266088Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.252265Z",
          "shell.execute_reply": "2025-07-03T09:45:26.265326Z"
        },
        "id": "_Q245JcAeUrP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_imp = DataLoader(train_dataset_imp, batch_size=32, shuffle=True)\n",
        "val_loader_imp   = DataLoader(val_dataset_imp, batch_size=32)\n",
        "test_loader_imp  = DataLoader(test_dataset_imp, batch_size=32)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.266869Z",
          "iopub.execute_input": "2025-07-03T09:45:26.26707Z",
          "iopub.status.idle": "2025-07-03T09:45:26.283047Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.267048Z",
          "shell.execute_reply": "2025-07-03T09:45:26.282415Z"
        },
        "id": "BFFzLj45eUrQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_imp = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.283877Z",
          "iopub.execute_input": "2025-07-03T09:45:26.284083Z",
          "iopub.status.idle": "2025-07-03T09:45:26.769015Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.284069Z",
          "shell.execute_reply": "2025-07-03T09:45:26.768194Z"
        },
        "id": "5TYkhhDbeUrQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unlock layers layer3, layer4**"
      ],
      "metadata": {
        "id": "9pYn64MBeUrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_imp.named_parameters():\n",
        "    if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.76985Z",
          "iopub.execute_input": "2025-07-03T09:45:26.77013Z",
          "iopub.status.idle": "2025-07-03T09:45:26.775276Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.770107Z",
          "shell.execute_reply": "2025-07-03T09:45:26.774492Z"
        },
        "id": "1soawNxQeUrR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.776101Z",
          "iopub.execute_input": "2025-07-03T09:45:26.776326Z",
          "iopub.status.idle": "2025-07-03T09:45:26.79349Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.776311Z",
          "shell.execute_reply": "2025-07-03T09:45:26.792803Z"
        },
        "id": "WRdyrhGleUrR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "in_features = model_imp.fc.in_features\n",
        "model_imp.fc = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(in_features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(256, num_classes)\n",
        ")\n",
        "\n",
        "model_imp = model_imp.to(device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.796692Z",
          "iopub.execute_input": "2025-07-03T09:45:26.796882Z",
          "iopub.status.idle": "2025-07-03T09:45:26.854086Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.796868Z",
          "shell.execute_reply": "2025-07-03T09:45:26.85336Z"
        },
        "id": "F4yriQRoeUrS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_imp = nn.CrossEntropyLoss()\n",
        "optimizer_imp = optim.Adam(filter(lambda p: p.requires_grad, model_imp.parameters()), lr=1e-4)\n",
        "scheduler_imp = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.854824Z",
          "iopub.execute_input": "2025-07-03T09:45:26.85508Z",
          "iopub.status.idle": "2025-07-03T09:45:26.859991Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.855061Z",
          "shell.execute_reply": "2025-07-03T09:45:26.859284Z"
        },
        "id": "mcjuF1nCeUrS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model_imp, loader):\n",
        "    model_imp.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model_imp(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return correct / total"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.860651Z",
          "iopub.execute_input": "2025-07-03T09:45:26.860879Z",
          "iopub.status.idle": "2025-07-03T09:45:26.876601Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.860863Z",
          "shell.execute_reply": "2025-07-03T09:45:26.87588Z"
        },
        "id": "cSL4PoXneUrT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs =15\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "def evaluate_loss_acc(model_imp, loader, criterion_imp, device):\n",
        "    model_imp.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_imp(images)\n",
        "            loss = criterion_imp(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_imp.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader_imp:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer_imp.zero_grad()\n",
        "        outputs = model_imp(images)\n",
        "        loss = criterion_imp(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_imp.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_train += (preds == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total_train\n",
        "    train_acc = correct_train / total_train\n",
        "\n",
        "    test_loss, test_acc = evaluate_loss_acc(model_imp, test_loader_imp, criterion_imp, device)\n",
        "    val_loss, val_acc = evaluate_loss_acc(model_imp, val_loader_imp, criterion_imp, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "\n",
        "    scheduler_imp.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | \"\n",
        "          f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:45:26.877401Z",
          "iopub.execute_input": "2025-07-03T09:45:26.877702Z",
          "iopub.status.idle": "2025-07-03T09:51:37.591718Z",
          "shell.execute_reply.started": "2025-07-03T09:45:26.877686Z",
          "shell.execute_reply": "2025-07-03T09:51:37.590937Z"
        },
        "id": "drb0eRnteUrT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_imp.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader_imp:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_imp(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Validation accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:51:37.592329Z",
          "iopub.execute_input": "2025-07-03T09:51:37.592545Z",
          "iopub.status.idle": "2025-07-03T09:51:40.255275Z",
          "shell.execute_reply.started": "2025-07-03T09:51:37.592529Z",
          "shell.execute_reply": "2025-07-03T09:51:40.254502Z"
        },
        "id": "-Am3C5eEeUrU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_imp.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader_imp:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_imp(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test data: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:51:40.256117Z",
          "iopub.execute_input": "2025-07-03T09:51:40.256789Z",
          "iopub.status.idle": "2025-07-03T09:51:42.883227Z",
          "shell.execute_reply.started": "2025-07-03T09:51:40.256764Z",
          "shell.execute_reply": "2025-07-03T09:51:42.882606Z"
        },
        "id": "B3a3se_seUrU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.utils as vutils\n",
        "\n",
        "def show_predictions(model_imp, loader, classes, device, n=16):\n",
        "    model_imp.eval()\n",
        "    images, labels = next(iter(loader))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model_imp(images)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    images = images.cpu()\n",
        "    fig = plt.figure(figsize=(15, 6))\n",
        "    for idx in range(min(n, len(images))):\n",
        "        ax = fig.add_subplot(2, n//2, idx+1, xticks=[], yticks=[])\n",
        "        img = images[idx]\n",
        "        img = img.permute(1, 2, 0)\n",
        "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
        "        img = img.clamp(0, 1)\n",
        "        ax.imshow(img.numpy())\n",
        "        ax.set_title(f\"P: {classes[preds[idx]]}\\nT: {classes[labels[idx]]}\",\n",
        "                     color=(\"green\" if preds[idx]==labels[idx] else \"red\"))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_predictions(model_imp, val_loader_imp, full_dataset_imp.classes, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:51:42.883933Z",
          "iopub.execute_input": "2025-07-03T09:51:42.884462Z",
          "iopub.status.idle": "2025-07-03T09:51:44.014282Z",
          "shell.execute_reply.started": "2025-07-03T09:51:42.884437Z",
          "shell.execute_reply": "2025-07-03T09:51:44.013537Z"
        },
        "id": "XKWax78_eUrU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range = range(1, num_epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, train_losses, label='Train Loss')\n",
        "plt.plot(epochs_range, test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, train_accuracies, label='Train Accuracy')\n",
        "plt.plot(epochs_range, test_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T09:51:44.015165Z",
          "iopub.execute_input": "2025-07-03T09:51:44.015393Z",
          "iopub.status.idle": "2025-07-03T09:51:44.377022Z",
          "shell.execute_reply.started": "2025-07-03T09:51:44.015376Z",
          "shell.execute_reply": "2025-07-03T09:51:44.376214Z"
        },
        "id": "XHrLQBrdeUrV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normal CNN"
      ],
      "metadata": {
        "id": "47sytIjaeUrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir\n",
        "\n",
        "transform_CNN = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "full_dataset_CNN = datasets.ImageFolder(data_dir, transform=transform_CNN)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T10:02:57.53053Z",
          "iopub.execute_input": "2025-07-03T10:02:57.53084Z",
          "iopub.status.idle": "2025-07-03T10:02:57.558742Z",
          "shell.execute_reply.started": "2025-07-03T10:02:57.530819Z",
          "shell.execute_reply": "2025-07-03T10:02:57.558213Z"
        },
        "id": "skuxLmdLeUrW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_size_CNN = int(0.7 * len(full_dataset_CNN))\n",
        "val_size_CNN = int(0.15 * len(full_dataset_CNN))\n",
        "test_size_CNN = len(full_dataset_CNN) - train_size_CNN - val_size_CNN\n",
        "\n",
        "train_dataset_CNN, val_dataset_CNN, test_dataset_CNN = random_split(full_dataset_CNN, [train_size_CNN, val_size_CNN, test_size_CNN])\n",
        "\n",
        "train_loader_CNN = DataLoader(train_dataset_CNN, batch_size=64, shuffle=True)\n",
        "val_loader_CNN = DataLoader(val_dataset_CNN, batch_size=64)\n",
        "test_loader_CNN = DataLoader(test_dataset_CNN, batch_size=64)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T10:04:29.611423Z",
          "iopub.execute_input": "2025-07-03T10:04:29.611964Z",
          "iopub.status.idle": "2025-07-03T10:04:29.61767Z",
          "shell.execute_reply.started": "2025-07-03T10:04:29.611941Z",
          "shell.execute_reply": "2025-07-03T10:04:29.616914Z"
        },
        "id": "7vUlJ0PzeUrX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_CNN = nn.CrossEntropyLoss()\n",
        "optimizer_CNN = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T10:20:10.272531Z",
          "iopub.execute_input": "2025-07-03T10:20:10.273189Z",
          "iopub.status.idle": "2025-07-03T10:20:10.277347Z",
          "shell.execute_reply.started": "2025-07-03T10:20:10.273166Z",
          "shell.execute_reply": "2025-07-03T10:20:10.276481Z"
        },
        "id": "9bC0E5fTeUrX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes_CNN):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 3, 64, 64)\n",
        "            dummy = self.features(dummy)\n",
        "            print(\"Shape after features:\", dummy.shape)  # np. torch.Size([1, 128, 8, 8])\n",
        "            n_features = dummy.shape[1] * dummy.shape[2] * dummy.shape[3]\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(n_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes_CNN)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "num_classes_CNN = len(full_dataset_CNN.classes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_CNN = SimpleCNN(num_classes_CNN).to(device)\n",
        "\n",
        "criterion_CNN = nn.CrossEntropyLoss()\n",
        "optimizer_CNN = optim.Adam(model_CNN.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T10:22:48.346855Z",
          "iopub.execute_input": "2025-07-03T10:22:48.34714Z",
          "iopub.status.idle": "2025-07-03T10:22:48.378265Z",
          "shell.execute_reply.started": "2025-07-03T10:22:48.347118Z",
          "shell.execute_reply": "2025-07-03T10:22:48.377482Z"
        },
        "id": "iLz_FQR0eUrY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs_CNN = 15\n",
        "\n",
        "train_losses_CNN = []\n",
        "val_losses_CNN = []\n",
        "train_accuracies_CNN = []\n",
        "val_accuracies_CNN = []\n",
        "test_losses_CNN = []\n",
        "test_accuracies_CNN = []\n",
        "\n",
        "for epoch in range(num_epochs_CNN):\n",
        "    model_CNN.train()\n",
        "    running_loss_CNN = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader_CNN:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer_CNN.zero_grad()\n",
        "        outputs = model_CNN(images)\n",
        "        loss = criterion_CNN(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_CNN.step()\n",
        "\n",
        "        running_loss_CNN += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    model_CNN.eval()\n",
        "    val_correct_CNN = 0\n",
        "    val_total_CNN = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader_CNN:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_CNN(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_correct_CNN += (predicted == labels).sum().item()\n",
        "            val_total_CNN += labels.size(0)\n",
        "\n",
        "    train_loss_CNN = running_loss_CNN / total_train\n",
        "    train_acc_CNN = correct_train / total_train\n",
        "\n",
        "\n",
        "    test_loss_CNN, test_acc_CNN = evaluate_loss_acc(model_CNN, test_loader_CNN, criterion_CNN, device)\n",
        "    val_loss_CNN, val_acc_CNN = evaluate_loss_acc(model_CNN, val_loader_CNN, criterion_CNN, device)\n",
        "\n",
        "    train_losses_CNN.append(train_loss_CNN)\n",
        "    val_losses_CNN.append(val_loss_CNN)\n",
        "    train_accuracies_CNN.append(train_acc_CNN)\n",
        "    val_accuracies_CNN.append(val_acc_CNN)\n",
        "    test_losses_CNN.append(test_loss_CNN)\n",
        "    test_accuracies_CNN.append(test_acc_CNN)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_CNN}, Loss: {train_loss_CNN:.4f}, Train Acc: {train_acc_CNN:.4f}, Val Acc: {val_acc_CNN:.4f},, Test Acc: {test_acc_CNN:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T10:44:40.230055Z",
          "iopub.execute_input": "2025-07-03T10:44:40.230787Z",
          "iopub.status.idle": "2025-07-03T10:46:52.780791Z",
          "shell.execute_reply.started": "2025-07-03T10:44:40.230764Z",
          "shell.execute_reply": "2025-07-03T10:46:52.780161Z"
        },
        "id": "hIzllHMxeUrZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range_CNN = range(1, num_epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range_CNN, train_losses_CNN, label='Train Loss')\n",
        "plt.plot(epochs_range_CNN, test_losses_CNN, label='Test Loss')\n",
        "plt.plot(epochs_range_CNN, val_losses_CNN, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range_CNN, train_accuracies_CNN, label='Train Accuracy')\n",
        "plt.plot(epochs_range_CNN, test_accuracies_CNN, label='Test Accuracy')\n",
        "plt.plot(epochs_range_CNN, val_accuracies_CNN, label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T10:47:18.581776Z",
          "iopub.execute_input": "2025-07-03T10:47:18.582072Z",
          "iopub.status.idle": "2025-07-03T10:47:18.936427Z",
          "shell.execute_reply.started": "2025-07-03T10:47:18.582041Z",
          "shell.execute_reply": "2025-07-03T10:47:18.935747Z"
        },
        "id": "CxsRkzxOeUra"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader_CNN:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_CNN(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Validation accuracy CNN: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T10:47:28.557436Z",
          "iopub.execute_input": "2025-07-03T10:47:28.557741Z",
          "iopub.status.idle": "2025-07-03T10:47:29.68183Z",
          "shell.execute_reply.started": "2025-07-03T10:47:28.557719Z",
          "shell.execute_reply": "2025-07-03T10:47:29.681179Z"
        },
        "id": "MYn4rERceUrb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader_CNN:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_CNN(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test data CNN: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-03T10:48:14.857442Z",
          "iopub.execute_input": "2025-07-03T10:48:14.858032Z",
          "iopub.status.idle": "2025-07-03T10:48:16.054458Z",
          "shell.execute_reply.started": "2025-07-03T10:48:14.85801Z",
          "shell.execute_reply": "2025-07-03T10:48:16.053718Z"
        },
        "id": "EGLzoiXleUrc"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}